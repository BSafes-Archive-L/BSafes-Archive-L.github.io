---
layout: default
title: The life of AI 
parent: § Leadership is needed for ethical ChatGPT - Character, assessment, and learning using artificial intelligence (AI)  
grand_parent: L
nav_order: 20 
---
<style>
.dont-break-out {
  /* These are technically the same, but use both */
  overflow-wrap: break-word;
  word-wrap: break-word;

     -ms-word-break: break-all;
  /* This is the dangerous one in WebKit, as it breaks things wherever */
  word-break: break-all;
  /* Instead use this non-standard one: */
  word-break: break-word;
}

.youtube-container {
    position: relative;
    width: 100%;
    height: 0;
    padding-bottom: 56.25%;
}
.youtube-video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
}

</style>

<div class="dont-break-out" markdown="1">

1. TOC
{:toc}

## The life of AI 
### The artificial intelligence history 
Artificial intelligence as a technology has existed for close to 70 years. It was in the 1950s that McCarthy first proposed the idea that machines could be intelligent (see McCarthy et al., 1955, McCarthy, 1987). The supporters of the original proposal included organisational research scholar Simon Herbert, and game theorist John Nash, among others. The $13,500 [~$150,701 in 2023 terms] proposal signalled a significant move in understanding artificial intelligence among the scholarly community.

Since then, we have progressed through models for artificial intelligence that began with toy problems such as checkers and basic chat, but quickly progressed to more advanced symbolic AI systems such as decision support based expert systems, and algorithmic planning systems.  These systems were able to elevate the field of AI from beyond the toy problems to providing automation and support for business and education (Ragheb et al., 2022), whether through decision support in a diagnostic setting, or planning support for timetabling and rostering.

But it was the advent of Neural Networks, and subsequently Machine Learning in the late twentieth century that drove the push of AI into the public consciousness as a more general tool for improving quality of life (Abiodun et al., 2018). Starting with Neural Networks, society found themselves able to build machines that could forecast results and predict outcomes (Hamzaçebi et al., 2009), often with more precision than a human being. AI found itself being integrated into approaches beyond automation, where the expertise of the machine was at times considered greater than that of the human, and where the mechanics of how the machine built this expertise were not fully understood. 

It started with an evolution on the toy problems, with machines learning to play chess so that they could beat the Grand Champions, or to compete in Jeopardy! and score higher than the most skilled human players (Ferrucci et al., 2013; Hassabis, 2017). But simultaneously, researchers were also exploring how these machines could recognise images and sounds, to fully understand the world they existed in. And it was in the twenty first century that this work truly began to pay dividends, with AI (now often labelled Machine Learning) arriving in consumers’ devices to recognise voice and images, providing quality of life improvements for interacting with the machine via voice recognition, and searching for content via image.  

At the same time, as the twenty first century began, large corporations were realising the value in aggregating large amounts of data. Perhaps begun by Google in the late twentieth century to enable their search algorithms, the broad area of data warehousing and data analytics was quickly adopted by both Google and others to truly understand their customer base (Gregory et al., 2021), building targeted marketing campaigns and using their understanding of both individuals and groups to tailor their content (Makridakis, 2017). At the same time organisations such as Facebook learnt that they could leverage this ‘Big Data’ to construct profiles of individuals – sometimes, as with AI, more detailed and nuanced than what a human being would construct without machine assistance. Indeed, the progression of artificial intelligence has grown and accelerated in the past years, with the LLM AIs – like ChatGPT – creating radical change in the way people do, be, and learn.

### The advent of ChatGPT
It was into this environment in the third decade of the twenty-first century that AI researchers found themselves well positioned to combine these two new approaches – machine learning and big data – to push the broad field of AI forward, using insights from data and algorithms to build new creative content. It began with AI-based art generation systems, that could take a prompt from a user and generate unique and arguably creatively new art pieces with any subject and in any style desired (e.g., Carnovalina & Roda, 2020). These tools used a new technology called “Generative Pre-Trained Transformer (GPT)”, which whilst based on existing AI and Big Data algorithms, was able to combine them to produce content that seemed to take a significant leap from what had been produced before. 

It was in late 2022 however that GPT took the next step. While some thought AI might have stalled as a result of COVID-19 (Connor et al., 2021), it perhaps had not with the ChatGPT AI being introduced publicly from November 2022, and a stable release from February 2023. The popularity of the tool rose quickly from the tool’s public release, with an oft-quoted statistic that ChatGPT was able to reach 100 million users in less than 2 months (Hu, 2023). It seemed that the next evolution of Machine Learning had arrived (see Rudolph et al., 2023 for a more extended summary of emergence). To illustrate why this tool caused such a stir, when we asked ChatGPT “Describe in one sentence why you were made” it said:

>> *I was made to provide conversational assistance and answer a wide range of questions
to help people find information and complete tasks more easily*

But this is not just a preformatted answer. Instead, if we were to ask again, we’d be given a slightly different but similar result:

>> *I was made to provide natural language processing and generate human-like responses
to facilitate communication between humans and machines.*

This is because ChatGPT uses a new technique to generate output. Rather than predicting or forecasting a right or wrong answer based on inputs as AI has done in the past, ChatGPT generates its output based on the prompt, using a pre-trained model that has been built from a large corpus of data (big data) that ChatGPT has scraped the internet for. Using this data, ChatGPT creates sentences and paragraphs based on what others have said about a topic in the past, stringing together words to construct a novel and creative answer that is slightly different each time. Intriguingly, this means that ChatGPT does not actually understand what it’s saying, but in the classic approach, leaves us to wonder that if it ‘looks like a duck and quacks like a duck’, does it matter whether it actually is a duck? The net result is still a novel and quite reasonable output, and it is in producing this that ChatGPT has created a significant level of concern in the higher education sector. 

***

#### Table of Contents
{: .no_toc}

<ul><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-1/">Introduction</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-2/">The life of AI</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-3/">The good and the bad of AI ChatGPT</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-4/">The missing strand of ChatGPT research and practice</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-5/">Conclusion</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-6/">Acknowledgement</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-7/">Conflict of Interest</a></li><li> <a href="/docs/L/Leadership-is-needed-for-ethical-ChatGPT-8/">References</a></li></ul>

***

</div>
